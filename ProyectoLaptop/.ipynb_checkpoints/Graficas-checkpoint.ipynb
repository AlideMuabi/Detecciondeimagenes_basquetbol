{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2465a61-6d4e-4f75-ae70-3885baf41608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results...\n",
      "Loaded data for Model 1 (YOLOv8n)\n",
      "Loaded data for Model 2 (YOLOv5nu)\n",
      "Loaded data for Model 3 (YOLO11n)\n",
      "Saved plot: comparison_map_50_95_vs_epoch.png\n",
      "Saved plot: comparison_map_50_vs_epoch.png\n",
      "Saved plot: comparison_precision_vs_epoch.png\n",
      "Saved plot: comparison_recall_vs_epoch.png\n",
      "Saved plot: comparison_final_map_bar_chart.png\n",
      "Saved plot: comparison_final_precision_recall_bar_chart.png\n",
      "Saved plot: comparison_final_inference_speed_bar_chart.png\n",
      "Saved plot: comparison_speed_vs_map_scatter.png\n",
      "\n",
      "--- Final Metrics Summary ---\n",
      "Model                     | Epochs | mAP@.5:.95 | mAP@.5     | Precision  | Recall     | Latency (ms/img)  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model 1 (YOLOv8n)         | 10     | 0.3392     | 0.5321     | 0.6050     | 0.5162     | 61.7              \n",
      "Model 2 (YOLOv5nu)        | 10     | 0.3106     | 0.5082     | 0.5847     | 0.4953     | 57.4              \n",
      "Model 3 (YOLO11n)         | 10     | 0.3160     | 0.5036     | 0.6052     | 0.4761     | 64.6              \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # Added for bar chart positioning\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# 1. DEFINE PATHS TO YOUR RESULTS.CSV FILES\n",
    "#    Replace these with the actual paths to your results files\n",
    "results_paths = {\n",
    "    \"Model 1 (YOLOv8n)\": \"/home/alide/Documentos/IA/Proyecto/runs_10epochs_4batch/detect/train_Yv8n/results.csv\",\n",
    "    \"Model 2 (YOLOv5nu)\": \"/home/alide/Documentos/IA/Proyecto/runs_10epochs_4batch/detect/train_Yv5nu/results.csv\",\n",
    "    \"Model 3 (YOLO11n)\": \"/home/alide/Documentos/IA/Proyecto/runs_10epochs_4batch/detect/train_Y11n/results.csv\",\n",
    "    # Add more models if needed\n",
    "}\n",
    "\n",
    "# 2. MANUALLY ENTER INFERENCE SPEED (e.g., FPS or ms per image)\n",
    "#    Obtain these values from your validation logs or benchmarking.\n",
    "#    Make sure the keys match the model names in results_paths EXACTLY.\n",
    "#    Specify the unit in the variable name or comments for clarity.\n",
    "#inference_speed_fps = {\n",
    "#    \"Model 1 (YOLOv8n)\": 150.5, # Example FPS value\n",
    "#    \"Model 2 (YOLOv8s)\": 95.2,  # Example FPS value\n",
    "#    \"Model 3 (YOLOv8m)\": 60.8,  # Example FPS value\n",
    "#}\n",
    "# OR use latency (milliseconds per image)\n",
    "inference_latency_ms = {\n",
    "    \"Model 1 (YOLOv8n)\": 61.7,\n",
    "    \"Model 2 (YOLOv5nu)\": 57.4,\n",
    "    \"Model 3 (YOLO11n)\": 64.6,\n",
    "}\n",
    "speed_metric_label = 'Latency (ms/img)' # Adjust label if using latency\n",
    "#speed_metric_label = 'Inference Speed (FPS)' # Adjust label if using FPS\n",
    "\n",
    "\n",
    "# 3. DEFINE THE METRIC COLUMNS TO PLOT FROM results.csv\n",
    "#    Check your results.csv header for the exact names. Common names:\n",
    "#    YOLOv8: 'metrics/mAP50-95(B)', 'metrics/mAP50(B)', 'metrics/precision(B)', 'metrics/recall(B)'\n",
    "#    YOLOv5: ' metrics/mAP_0.5:0.95', ' metrics/mAP_0.5', ' metrics/precision', ' metrics/recall' (Note potential leading space)\n",
    "map_50_95_col = 'metrics/mAP50-95(B)'\n",
    "map_50_col = 'metrics/mAP50(B)'\n",
    "precision_col = 'metrics/precision(B)' # Use ' metrics/precision' for YOLOv5 if needed\n",
    "recall_col = 'metrics/recall(B)'       # Use ' metrics/recall' for YOLOv5 if needed\n",
    "epoch_col = 'epoch'\n",
    "\n",
    "# 4. (Optional) Set plot styling\n",
    "plt.style.use('seaborn-v0_8') # Use 'default' or other styles if you prefer\n",
    "\n",
    "# --- Data Loading and Processing ---\n",
    "model_data = {}\n",
    "final_metrics = {}\n",
    "model_names_loaded = []\n",
    "\n",
    "print(\"Loading results...\")\n",
    "for model_name, path in results_paths.items():\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Warning: Results file not found for {model_name} at {path}. Skipping.\")\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        # Clean up column names (remove leading/trailing spaces)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        model_data[model_name] = df\n",
    "        model_names_loaded.append(model_name)\n",
    "\n",
    "        # Store final metrics (last epoch) - Check if columns exist\n",
    "        metrics_to_store = {}\n",
    "        metrics_to_store['epochs'] = df[epoch_col].iloc[-1]\n",
    "        if map_50_95_col in df.columns:\n",
    "            metrics_to_store['mAP50-95'] = df[map_50_95_col].iloc[-1]\n",
    "        if map_50_col in df.columns:\n",
    "            metrics_to_store['mAP50'] = df[map_50_col].iloc[-1]\n",
    "        if precision_col in df.columns:\n",
    "             metrics_to_store['Precision'] = df[precision_col].iloc[-1]\n",
    "        if recall_col in df.columns:\n",
    "            metrics_to_store['Recall'] = df[recall_col].iloc[-1]\n",
    "\n",
    "        # Add inference speed (handle missing entries)\n",
    "        speed_value = inference_latency_ms.get(model_name, None) # Use if tracking latency\n",
    "        #speed_value = inference_speed_fps.get(model_name, None) # Use if tracking FPS\n",
    "        if speed_value is not None:\n",
    "             metrics_to_store['Speed'] = speed_value\n",
    "        else:\n",
    "             print(f\"Warning: Inference speed not found for {model_name} in configuration.\")\n",
    "             metrics_to_store['Speed'] = None # Or np.nan\n",
    "\n",
    "        final_metrics[model_name] = metrics_to_store\n",
    "        print(f\"Loaded data for {model_name}\")\n",
    "\n",
    "    except KeyError as e:\n",
    "         print(f\"Error loading {model_name}: Missing expected column: {e}. Please check column names in config.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing {model_name} from {path}: {e}\")\n",
    "\n",
    "if not model_data:\n",
    "    print(\"No data loaded. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# --- Plotting Function ---\n",
    "def plot_metric_vs_epoch(metric_col, title, ylabel, filename):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    all_found = True\n",
    "    for model_name, df in model_data.items():\n",
    "        if metric_col in df.columns and epoch_col in df.columns:\n",
    "            # Add 1 to epoch so it starts from 1 instead of 0 if needed\n",
    "            plt.plot(df[epoch_col] + 1, df[metric_col], marker='.', linestyle='-', label=model_name)\n",
    "        else:\n",
    "             print(f\"Warning: Column '{metric_col}' or '{epoch_col}' not found for {model_name}. Cannot plot {title}.\")\n",
    "             all_found = False\n",
    "\n",
    "    if not plt.gca().lines and not all_found: # No lines were plotted and we had warnings\n",
    "         print(f\"Skipping plot '{title}' as no data could be plotted.\")\n",
    "         plt.close() # Close the empty figure\n",
    "         return False\n",
    "    elif not plt.gca().lines:\n",
    "        print(f\"Skipping plot '{title}' as no models had the required column '{metric_col}'.\")\n",
    "        plt.close()\n",
    "        return False\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    print(f\"Saved plot: {filename}\")\n",
    "    #plt.show() # Uncomment to display plot immediately\n",
    "    plt.close() # Close the figure after saving to free memory\n",
    "    return True\n",
    "\n",
    "# --- Generate Plots ---\n",
    "\n",
    "# 1. mAP Plots vs Epoch\n",
    "plot_metric_vs_epoch(map_50_95_col, 'Model Comparison: mAP@0.5:0.95 vs Epoch', 'mAP@0.5:0.95', 'comparison_map_50_95_vs_epoch.png')\n",
    "plot_metric_vs_epoch(map_50_col, 'Model Comparison: mAP@0.5 vs Epoch', 'mAP@0.5', 'comparison_map_50_vs_epoch.png')\n",
    "\n",
    "# 2. Precision & Recall Plots vs Epoch\n",
    "plot_metric_vs_epoch(precision_col, 'Model Comparison: Precision vs Epoch', 'Precision', 'comparison_precision_vs_epoch.png')\n",
    "plot_metric_vs_epoch(recall_col, 'Model Comparison: Recall vs Epoch', 'Recall', 'comparison_recall_vs_epoch.png')\n",
    "\n",
    "\n",
    "# --- Plotting Final Metrics ---\n",
    "\n",
    "# Helper function for adding bar labels\n",
    "def add_bar_labels(ax, bars):\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.4f}', va='bottom', ha='center', fontsize=9) # Adjust fontsize if needed\n",
    "\n",
    "# 3. Bar chart of Final mAP Scores\n",
    "final_map_50_95 = {name: metrics.get('mAP50-95', np.nan) for name, metrics in final_metrics.items() if name in model_names_loaded}\n",
    "final_map_50 = {name: metrics.get('mAP50', np.nan) for name, metrics in final_metrics.items() if name in model_names_loaded}\n",
    "\n",
    "if any(pd.notna(v) for v in final_map_50_95.values()) or any(pd.notna(v) for v in final_map_50.values()):\n",
    "    fig_map, ax_map = plt.subplots(1, 2, figsize=(15, 6), sharey=False)\n",
    "    fig_map.suptitle('Comparison of Final Model mAP', fontsize=16)\n",
    "\n",
    "    # mAP@0.5:0.95\n",
    "    bars1 = ax_map[0].bar(final_map_50_95.keys(), final_map_50_95.values(), color='#1f77b4')\n",
    "    ax_map[0].set_title('Final mAP@0.5:0.95')\n",
    "    ax_map[0].set_ylabel('mAP@0.5:0.95')\n",
    "    ax_map[0].tick_params(axis='x', rotation=15)\n",
    "    add_bar_labels(ax_map[0], bars1)\n",
    "    ax_map[0].set_ylim(bottom=0, top=max(final_map_50_95.values()) * 1.1 if any(pd.notna(v) for v in final_map_50_95.values()) else 1) # Adjust y-axis\n",
    "\n",
    "    # mAP@0.5\n",
    "    bars2 = ax_map[1].bar(final_map_50.keys(), final_map_50.values(), color='#ff7f0e')\n",
    "    ax_map[1].set_title('Final mAP@0.5')\n",
    "    ax_map[1].set_ylabel('mAP@0.5')\n",
    "    ax_map[1].tick_params(axis='x', rotation=15)\n",
    "    add_bar_labels(ax_map[1], bars2)\n",
    "    ax_map[1].set_ylim(bottom=0, top=max(final_map_50.values()) * 1.1 if any(pd.notna(v) for v in final_map_50.values()) else 1) # Adjust y-axis\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig('comparison_final_map_bar_chart.png')\n",
    "    print(\"Saved plot: comparison_final_map_bar_chart.png\")\n",
    "    plt.close(fig_map)\n",
    "else:\n",
    "    print(\"Skipping final mAP bar chart: No mAP data available.\")\n",
    "\n",
    "\n",
    "# 4. Bar chart of Final Precision & Recall\n",
    "final_precision = {name: metrics.get('Precision', np.nan) for name, metrics in final_metrics.items() if name in model_names_loaded}\n",
    "final_recall = {name: metrics.get('Recall', np.nan) for name, metrics in final_metrics.items() if name in model_names_loaded}\n",
    "\n",
    "if any(pd.notna(v) for v in final_precision.values()) or any(pd.notna(v) for v in final_recall.values()):\n",
    "    fig_pr, ax_pr = plt.subplots(1, 2, figsize=(15, 6), sharey=True) # Share Y axis often makes sense here\n",
    "    fig_pr.suptitle('Comparison of Final Model Precision & Recall', fontsize=16)\n",
    "\n",
    "    # Precision\n",
    "    bars_p = ax_pr[0].bar(final_precision.keys(), final_precision.values(), color='#2ca02c')\n",
    "    ax_pr[0].set_title('Final Precision')\n",
    "    ax_pr[0].set_ylabel('Score')\n",
    "    ax_pr[0].tick_params(axis='x', rotation=15)\n",
    "    add_bar_labels(ax_pr[0], bars_p)\n",
    "\n",
    "    # Recall\n",
    "    bars_r = ax_pr[1].bar(final_recall.keys(), final_recall.values(), color='#d62728')\n",
    "    ax_pr[1].set_title('Final Recall')\n",
    "    ax_pr[1].set_ylabel('Recall') # Y label shared\n",
    "    ax_pr[1].tick_params(axis='x', rotation=15)\n",
    "    add_bar_labels(ax_pr[1], bars_r)\n",
    "\n",
    "    # Set shared Y-axis limits appropriately\n",
    "    max_pr = max(list(final_precision.values()) + list(final_recall.values()))\n",
    "    if pd.notna(max_pr):\n",
    "      ax_pr[0].set_ylim(bottom=0, top=max_pr * 1.1)\n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig('comparison_final_precision_recall_bar_chart.png')\n",
    "    print(\"Saved plot: comparison_final_precision_recall_bar_chart.png\")\n",
    "    plt.close(fig_pr)\n",
    "else:\n",
    "     print(\"Skipping final Precision/Recall bar chart: No Precision/Recall data available.\")\n",
    "\n",
    "\n",
    "# 5. Bar chart of Inference Speed\n",
    "final_speed = {name: metrics.get('Speed', np.nan) for name, metrics in final_metrics.items() if name in model_names_loaded}\n",
    "\n",
    "if any(pd.notna(v) for v in final_speed.values()):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars_s = plt.bar(final_speed.keys(), final_speed.values(), color='#9467bd')\n",
    "    plt.title('Comparison of Model Inference Speed')\n",
    "    plt.ylabel(speed_metric_label) # Use configured label\n",
    "    plt.xticks(rotation=15)\n",
    "    # Add labels for speed (adjust formatting if needed, e.g., fewer decimal places for FPS)\n",
    "    for bar in bars_s:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.1f}', va='bottom', ha='center', fontsize=10) # .1f format for speed\n",
    "    plt.ylim(bottom=0, top=max(final_speed.values()) * 1.1 if any(pd.notna(v) for v in final_speed.values()) else 1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('comparison_final_inference_speed_bar_chart.png')\n",
    "    print(\"Saved plot: comparison_final_inference_speed_bar_chart.png\")\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"Skipping inference speed bar chart: No speed data available.\")\n",
    "\n",
    "# 6. Scatter Plot: Speed vs. Accuracy (mAP@0.5:0.95)\n",
    "if any(pd.notna(v) for v in final_speed.values()) and any(pd.notna(v) for v in final_map_50_95.values()):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    # Ensure only models with both speed and mAP are plotted\n",
    "    plot_names = [name for name in model_names_loaded if pd.notna(final_speed.get(name)) and pd.notna(final_map_50_95.get(name))]\n",
    "    plot_speeds = [final_speed[name] for name in plot_names]\n",
    "    plot_maps = [final_map_50_95[name] for name in plot_names]\n",
    "\n",
    "    if plot_names: # Only plot if we have valid data points\n",
    "        scatter = plt.scatter(plot_speeds, plot_maps, s=100, alpha=0.7, c=range(len(plot_names)), cmap='viridis') # Size=100, transparency=0.7, color varies\n",
    "        plt.title('Model Trade-off: Inference Speed vs. mAP@0.5:0.95')\n",
    "        plt.xlabel(speed_metric_label)\n",
    "        plt.ylabel('mAP@0.5:0.95')\n",
    "\n",
    "        # Add model names as labels near the points\n",
    "        for i, name in enumerate(plot_names):\n",
    "            plt.annotate(name, (plot_speeds[i], plot_maps[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('comparison_speed_vs_map_scatter.png')\n",
    "        print(\"Saved plot: comparison_speed_vs_map_scatter.png\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        print(\"Skipping Speed vs. mAP scatter plot: Not enough data points with both metrics.\")\n",
    "else:\n",
    "     print(\"Skipping Speed vs. mAP scatter plot: Missing required speed or mAP data.\")\n",
    "\n",
    "\n",
    "# --- Final Summary Output ---\n",
    "print(\"\\n--- Final Metrics Summary ---\")\n",
    "print(f\"{'Model':<25} | {'Epochs':<6} | {'mAP@.5:.95':<10} | {'mAP@.5':<10} | {'Precision':<10} | {'Recall':<10} | {speed_metric_label:<18}\")\n",
    "print(\"-\" * 100)\n",
    "for name in model_names_loaded:\n",
    "    metrics = final_metrics.get(name, {})\n",
    "    epoch_val = metrics.get('epochs', 'N/A')\n",
    "    map_50_95_val = f\"{metrics.get('mAP50-95', 'N/A'):.4f}\" if isinstance(metrics.get('mAP50-95'), (int, float)) else 'N/A'\n",
    "    map_50_val = f\"{metrics.get('mAP50', 'N/A'):.4f}\" if isinstance(metrics.get('mAP50'), (int, float)) else 'N/A'\n",
    "    prec_val = f\"{metrics.get('Precision', 'N/A'):.4f}\" if isinstance(metrics.get('Precision'), (int, float)) else 'N/A'\n",
    "    rec_val = f\"{metrics.get('Recall', 'N/A'):.4f}\" if isinstance(metrics.get('Recall'), (int, float)) else 'N/A'\n",
    "    speed_val = f\"{metrics.get('Speed', 'N/A'):.1f}\" if isinstance(metrics.get('Speed'), (int, float)) else 'N/A' # Format speed\n",
    "\n",
    "    print(f\"{name:<25} | {epoch_val:<6} | {map_50_95_val:<10} | {map_50_val:<10} | {prec_val:<10} | {rec_val:<10} | {speed_val:<18}\")\n",
    "\n",
    "# Optional: Display all plots at the end if needed (might be many windows)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbacae9-f04a-402b-861e-b497c90b4585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
